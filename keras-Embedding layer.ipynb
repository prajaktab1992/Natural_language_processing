{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement: \n",
    "How embedding layer works in Keras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential() #create sequential model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=Embedding(input_dim=10,output_dim=4,input_length=2) # creates embedding for 10 vocabularies with output dimension (10,4) \n",
    "                                                        #and expects input sequence length of 2 (gives warning if >< 2)\n",
    "model.add(emb)# add layer to model\n",
    "model.compile('adam','mse') #compile above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_data=np.array([[1,2]])# create input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(input_data) #Predict for above input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.03176137,  0.04662043, -0.03105542,  0.00867708],\n",
       "        [ 0.03106494,  0.03647831,  0.04578931,  0.03198867]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import  Flatten,Embedding,Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=[\n",
    "        \"Never coming back!\",\n",
    "        \"Horrible service\",\n",
    "        \"Rude waitress\",\n",
    "         \"cold food.\",\n",
    "         \"Horrible food!\",\n",
    "         \"Awesome\",\n",
    "         \"Awesome service!\",\n",
    "         \"Rocks!\",\n",
    "         \"poor work\",\n",
    "        \"couldn\\'t have done better\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=array([1,1,1,1,1,0,0,0,0,0]) #1 -negative 0- positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded reviews : [[29, 7, 18], [31, 15], [29, 37], [4, 7], [31, 7], [48], [48, 15], [34], [9, 41], [4, 44, 12, 38]]\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE=50\n",
    "encoded_reviews=[one_hot(d,VOCAB_SIZE) for d in reviews]\n",
    "print(f\"Encoded reviews : {encoded_reviews }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sequences??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  7 18  0]\n",
      " [31 15  0  0]\n",
      " [29 37  0  0]\n",
      " [ 4  7  0  0]\n",
      " [31  7  0  0]\n",
      " [48  0  0  0]\n",
      " [48 15  0  0]\n",
      " [34  0  0  0]\n",
      " [ 9 41  0  0]\n",
      " [ 4 44 12 38]]\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH=4\n",
    "padded_reviews=pad_sequences(encoded_reviews,maxlen=MAX_LENGTH,padding=\"post\")\n",
    "print(padded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "embedding_layer=Embedding(VOCAB_SIZE,8,input_length=MAX_LENGTH)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['acc'])\n",
    "\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6875 - acc: 0.7000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6856 - acc: 0.8000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6836 - acc: 0.8000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6817 - acc: 0.8000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6798 - acc: 0.9000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.9000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6759 - acc: 0.9000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6740 - acc: 0.9000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6721 - acc: 0.9000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6701 - acc: 0.9000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6682 - acc: 0.9000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6662 - acc: 0.9000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6643 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6623 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6603 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6584 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6564 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6544 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6524 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6504 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6484 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6463 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6423 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6402 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6382 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6361 - acc: 1.000 - 0s 2ms/step - loss: 0.6361 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6340 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6319 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6298 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6277 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6256 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6234 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6213 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6191 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6169 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6147 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6125 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6103 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6081 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6058 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6036 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6013 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5990 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5967 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5944 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5921 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5897 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5874 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5850 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5827 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5803 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5779 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5755 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5730 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5706 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5681 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5657 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5632 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5607 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5582 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5557 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5532 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5507 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5481 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5456 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5430 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5405 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5379 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5353 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5327 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5301 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5275 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5249 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5223 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5196 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5170 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5143 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5117 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5064 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5037 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5010 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4983 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4957 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4930 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4903 - acc: 1.0000\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4876 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4849 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4822 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4795 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4768 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4741 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4714 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4687 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4606 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4578 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4551 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2e1a6fd1a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_reviews,labels,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.29968047e-01  6.17162436e-02  1.17176965e-01 -1.02523744e-01\n",
      "   1.20807678e-01  1.15326509e-01  1.38356417e-01  5.09862900e-02]\n",
      " [ 1.09456852e-03 -3.29487696e-02 -2.90077329e-02  8.42285156e-03\n",
      "  -3.79139557e-02  1.81378052e-03  2.55202688e-02 -3.30099687e-02]\n",
      " [-6.96761534e-03 -1.68717019e-02  2.13806070e-02 -1.48048401e-02\n",
      "   1.65809318e-03 -1.73527114e-02 -8.00790638e-03  3.81978489e-02]\n",
      " [ 3.11393030e-02  4.29348685e-02  4.87075932e-02  2.93940939e-02\n",
      "   1.33677572e-03  5.51140308e-03 -4.67559695e-02  3.51661332e-02]\n",
      " [ 8.81352425e-02  5.27929142e-02 -1.05815798e-01 -1.21042423e-01\n",
      "  -1.00462586e-01 -1.42243803e-01  8.08918551e-02  9.27122682e-02]\n",
      " [-4.55707088e-02 -5.52631915e-04  1.98621862e-02 -3.23953778e-02\n",
      "  -4.88193408e-02 -4.17602062e-02 -4.80681434e-02 -2.98222657e-02]\n",
      " [-1.88774951e-02  2.19022967e-02 -2.80194879e-02 -1.30860880e-03\n",
      "   3.11461203e-02  1.29497908e-02  3.75992097e-02 -2.53645070e-02]\n",
      " [-5.86785972e-02 -7.01396540e-02 -1.40762731e-01  1.18695214e-01\n",
      "   9.35560651e-03 -1.35521650e-01 -1.10750571e-01 -1.27683833e-01]\n",
      " [-4.24556397e-02  4.07266729e-02 -9.97539610e-03 -2.06188317e-02\n",
      "  -1.33673921e-02  3.18670906e-02 -4.90164757e-03  2.68569626e-02]\n",
      " [-9.14515406e-02 -1.34556726e-01  9.05044228e-02  6.34242147e-02\n",
      "   5.49075492e-02  8.29027668e-02 -1.26673192e-01 -1.42724425e-01]\n",
      " [ 4.23640013e-03 -3.55734006e-02 -1.10508204e-02 -4.93187904e-02\n",
      "  -4.79857437e-02  1.42432489e-02  4.09244373e-03  4.20517065e-02]\n",
      " [ 1.25067867e-02  1.46110393e-02 -1.92492083e-03  2.28690542e-02\n",
      "   4.07521836e-02  3.79562378e-03 -1.87987816e-02  1.99411847e-02]\n",
      " [ 9.76387188e-02 -1.02694646e-01  6.68379515e-02 -9.37688723e-02\n",
      "  -1.22248754e-01  1.27475083e-01 -1.50595024e-01 -1.34745255e-01]\n",
      " [-9.09968466e-03  4.36862223e-02 -9.83518362e-03  4.88616563e-02\n",
      "  -2.64338143e-02 -2.64047515e-02 -2.03845743e-02 -3.00364625e-02]\n",
      " [-2.47002244e-02 -6.04651123e-03 -1.48676261e-02  2.26532109e-02\n",
      "  -1.95120815e-02 -4.16937955e-02 -3.70015986e-02  1.99545361e-02]\n",
      " [ 6.49802834e-02  5.25361300e-02  6.46762922e-02  1.38555681e-02\n",
      "   1.27266755e-03  7.27983774e-04  5.99223934e-02 -6.26828847e-03]\n",
      " [-3.82411107e-02 -4.90934253e-02 -3.44904065e-02  4.68360074e-02\n",
      "  -1.94149259e-02 -1.84200890e-02  2.15382241e-02 -3.90871614e-03]\n",
      " [ 1.09307393e-02 -5.87474555e-04  2.45054811e-03  3.84833664e-03\n",
      "  -4.15587053e-02  4.61432226e-02  2.50221603e-02  2.00263374e-02]\n",
      " [-1.15858436e-01  9.32397917e-02 -5.67889176e-02  1.10605277e-01\n",
      "   1.51515841e-01 -1.23509370e-01  9.65963900e-02  1.07647032e-01]\n",
      " [-3.00792344e-02 -4.49350961e-02  1.05908290e-02 -2.16501113e-02\n",
      "  -5.84828854e-03 -2.54973900e-02 -4.27189246e-02  4.08614613e-02]\n",
      " [-2.82429531e-03 -2.22426187e-02 -4.82021682e-02  1.86186470e-02\n",
      "  -1.45632736e-02  1.59435384e-02  5.86863607e-03  4.91768830e-02]\n",
      " [-4.49360274e-02  4.05113772e-03  4.75732423e-02 -9.80272889e-05\n",
      "   2.61661448e-02 -1.03281513e-02  2.91157514e-04  6.23682886e-03]\n",
      " [ 3.79452147e-02 -1.73894316e-03  1.59896053e-02  2.07514055e-02\n",
      "  -4.53817025e-02 -2.34631188e-02  3.18273194e-02  7.46165588e-03]\n",
      " [ 1.82560794e-02  3.31926830e-02  1.63495205e-02  4.72126268e-02\n",
      "   1.47448815e-02  3.65808494e-02  4.45040800e-02  3.44441645e-02]\n",
      " [-3.18959504e-02 -1.00633614e-02  4.22343276e-02  4.36834246e-03\n",
      "   2.14618184e-02 -1.46330819e-02  3.34088542e-02 -2.56321579e-03]\n",
      " [-3.66509557e-02  2.18449906e-03 -4.78783511e-02  4.39799912e-02\n",
      "   2.21514367e-02  4.67577241e-02  3.83015163e-02  4.54802401e-02]\n",
      " [-5.26569039e-03  1.54675581e-02 -2.94220094e-02  3.72312777e-02\n",
      "  -8.59506056e-03 -2.74212714e-02  2.56055631e-02 -1.70829780e-02]\n",
      " [ 4.17270176e-02  9.84203815e-03 -2.09135059e-02  1.42088868e-02\n",
      "   4.60073352e-06 -6.25298172e-03 -1.77787319e-02 -4.47080508e-02]\n",
      " [-4.31331508e-02  7.94830173e-03 -4.36410904e-02 -8.18515942e-03\n",
      "   4.01460417e-02 -4.44927216e-02 -4.46897522e-02  1.12397894e-02]\n",
      " [ 1.29588857e-01  1.10869244e-01 -1.55573726e-01 -5.81126884e-02\n",
      "  -1.23669401e-01 -1.44443259e-01  1.21675603e-01  1.09655596e-01]\n",
      " [ 1.30152740e-02 -1.02142245e-03 -4.06780839e-02 -9.98090580e-03\n",
      "   2.76088752e-02 -2.91284807e-02  3.48196663e-02 -4.15399298e-02]\n",
      " [ 8.58007297e-02  1.35355577e-01 -1.32347032e-01 -1.51741192e-01\n",
      "  -1.28166720e-01 -1.11232840e-01  1.49577156e-01  9.94476750e-02]\n",
      " [ 4.21497971e-03 -4.29595597e-02  6.64278120e-03  3.74652408e-02\n",
      "   2.67859139e-02 -1.70503035e-02 -1.28114708e-02 -1.25065073e-02]\n",
      " [-3.25202495e-02  4.30699848e-02  1.35329403e-02 -2.91900709e-03\n",
      "   1.53660811e-02 -4.46629412e-02  4.17705812e-02  3.91998328e-02]\n",
      " [-7.06425384e-02 -6.23704232e-02  9.71766040e-02  8.72112066e-02\n",
      "   1.22582927e-01  1.29677355e-01 -6.04457073e-02 -8.94729123e-02]\n",
      " [ 1.99425109e-02  2.82262824e-02 -4.59876545e-02 -8.02788883e-03\n",
      "  -2.95766592e-02  3.03859971e-02 -4.61845063e-02  3.61189283e-02]\n",
      " [ 1.97387859e-03  2.24825032e-02  1.73954256e-02  2.70932056e-02\n",
      "   1.37071870e-02 -2.12809928e-02 -1.06652267e-02  2.07793973e-02]\n",
      " [-8.34340528e-02 -5.97508773e-02 -5.36518283e-02  8.39185864e-02\n",
      "   1.98619720e-02 -6.08825833e-02 -9.74521562e-02 -8.82711783e-02]\n",
      " [ 4.79777679e-02 -1.36795998e-01 -4.58372459e-02  7.91812316e-02\n",
      "  -1.27055958e-01 -1.47163615e-01 -7.34343976e-02 -6.36033565e-02]\n",
      " [ 2.64642127e-02 -8.41497257e-03  3.25024389e-02  4.05673720e-02\n",
      "  -4.78257984e-03  2.42971815e-02 -2.77158506e-02  1.97933950e-02]\n",
      " [ 1.35684870e-02  2.63268389e-02 -2.20258832e-02  2.85448469e-02\n",
      "   2.28868797e-03 -3.39581855e-02  3.10139097e-02  3.38459499e-02]\n",
      " [ 8.58865380e-02  1.39456809e-01  1.12271793e-01 -1.15197867e-01\n",
      "  -8.84981360e-03  1.24596782e-01  8.69404450e-02  1.24183737e-01]\n",
      " [-2.86065098e-02  3.10908891e-02  1.34457089e-02  4.06191014e-02\n",
      "  -2.93938052e-02  4.92532738e-02 -4.06253934e-02 -2.91854143e-02]\n",
      " [-2.11824775e-02 -4.14611101e-02 -3.01992651e-02 -4.91917729e-02\n",
      "   4.47567441e-02  4.92454693e-03 -2.57987976e-02  4.54595722e-02]\n",
      " [ 1.22071110e-01  5.97237535e-02  5.78774773e-02 -8.31126347e-02\n",
      "  -9.13300067e-02  1.43305942e-01  9.53501761e-02  1.06047824e-01]\n",
      " [-2.17896700e-02  2.32813619e-02 -3.59093919e-02 -4.73083369e-02\n",
      "   9.78476927e-03 -2.98169851e-02 -3.64877470e-02 -1.40475109e-03]\n",
      " [-3.44228856e-02  2.72350647e-02  2.78667472e-02  3.90278585e-02\n",
      "   1.04100704e-02  4.49652113e-02  1.51690356e-02 -1.55922398e-02]\n",
      " [-3.14020403e-02  6.79210573e-03  1.41622759e-02  2.60128416e-02\n",
      "   2.25042216e-02  1.32053606e-02 -4.96052019e-02  4.56475057e-02]\n",
      " [-1.09299392e-01 -9.67114568e-02  1.55067816e-01  5.48210628e-02\n",
      "   1.32809326e-01  7.69010186e-02 -1.11590348e-01 -9.99145359e-02]\n",
      " [-4.30989861e-02 -2.88922191e-02 -3.69221568e-02  3.23186629e-02\n",
      "   4.05478813e-02  1.60983466e-02 -1.84095018e-02  6.28753752e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 8)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy=model.evaluate(padded_reviews,labels,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45243263244628906"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
